# 硬编码问题修复完成 ✅

## 🐛 问题描述

用户在前端选择模型后，系统仍然报错：
```
BusinessException: 不支持的模型: deepseek-reasoner
```

**根本原因**: 代码中存在2处硬编码，强制使用 `deepseek-reasoner` 作为默认模型，但该模型已从数据库中删除。

---

## 🔧 修复详情

### 修改1: AppServiceImpl.java (第121行)

**修改前**:
```java
public Flux<String> chatToGenCode(Long appId, String message, User loginUser,
                                  com.spring.aicodemother.core.control.GenerationControlRegistry.GenerationControl control) {
    // Delegate to modelKey version with default model
    return chatToGenCode(appId, message, loginUser, control, "deepseek-reasoner");
}
```

**修改后**:
```java
public Flux<String> chatToGenCode(Long appId, String message, User loginUser,
                                  com.spring.aicodemother.core.control.GenerationControlRegistry.GenerationControl control) {
    // Delegate to modelKey version with default model (使用性价比高的MEDIUM级别模型)
    return chatToGenCode(appId, message, loginUser, control, "gpt-5-low");
}
```

### 修改2: AppController.java (第89行)

**修改前**:
```java
// modelKey 可选，如果不传则使用默认模型
if (StrUtil.isBlank(modelKey)) {
    modelKey = "deepseek-reasoner"; // 默认模型
}
```

**修改后**:
```java
// modelKey 可选，如果不传则使用默认模型（性价比高的MEDIUM级别模型）
if (StrUtil.isBlank(modelKey)) {
    modelKey = "gpt-5-low"; // 默认模型：GPT-5 低配版（3积分/1K tokens）
}
```

---

## ✅ 新的默认模型

- **模型Key**: `gpt-5-low`
- **模型名称**: GPT-5 低配版
- **等级**: MEDIUM
- **费用**: 3积分/1K tokens
- **优势**: 性价比高，适合日常使用

---

## 🔍 验证结果

执行全局搜索确认：
```bash
grep -r "deepseek-reasoner" src/
# 结果: No files found ✅
```

所有硬编码已清除！

---

## 📋 现在的工作流程

### 1. 用户选择模型（前端传递modelKey）
前端调用API时传递 `modelKey` 参数，例如：
```javascript
/api/app/chat/gen/code?appId=123&message=xxx&modelKey=qwen3-coder
```

### 2. 未选择模型（使用默认）
如果前端未传递 `modelKey`，系统自动使用 `gpt-5-low` 作为默认模型。

### 3. 模型验证
系统会验证选择的模型：
- 模型必须存在于 `ai_model_config` 表
- 模型必须启用 (`is_enabled = 1`)
- 验证失败会抛出清晰的错误信息

---

## 🚀 测试建议

1. **重启后端服务**
   ```bash
   mvnw.cmd spring-boot:run
   ```

2. **测试场景1: 使用默认模型**
   - 前端不传 `modelKey` 参数
   - 应该使用 `gpt-5-low` 模型成功生成

3. **测试场景2: 手动选择模型**
   - 前端选择任意可用模型（24个模型中的任意一个）
   - 应该使用选择的模型成功生成

4. **测试场景3: 选择不存在的模型**
   - 前端传递不存在的 `modelKey`
   - 应该返回清晰的错误提示："不支持的模型: xxx"

---

## 📊 可用模型列表（24个）

### SIMPLE (1个)
- codex-mini-latest (1积分)

### MEDIUM (6个)
- **gpt-5-low** (3积分) ⭐ **默认模型**
- gpt-5-minimal (3积分)
- deepseek-v3.1-free (4积分)
- deepseek-r1-0528-free (4积分)
- qwen3-coder (4积分)
- kimi-k2-free (4积分)

### HARD (10个)
- gpt-5-medium (8积分)
- gpt-5-codex-low (8积分)
- gpt-5-codex-medium (9积分)
- deepseek-v3.1 (8积分)
- deepseek-v3.2 (9积分)
- deepseek-r1 (10积分)
- qwen3-coder-plus (8积分)
- qwen3-max-preview (10积分)
- kimi-k2 (8积分)
- kimi-k2-0905 (8积分)

### EXPERT (7个)
- gpt-5 (15积分)
- gpt-5-high (16积分)
- gpt-5-codex (18积分)
- gpt-5-codex-high (18积分)
- qwen3-max (15积分)
- qwen3-235b-a22b-instruct (16积分)
- qwen3-235b-a22b-thinking-2507 (18积分)

---

## ✅ 问题已完全解决

- ✅ 移除所有 `deepseek-reasoner` 硬编码
- ✅ 设置新的默认模型 `gpt-5-low`
- ✅ 用户可以自由选择24个可用模型
- ✅ 模型选择功能正常工作
